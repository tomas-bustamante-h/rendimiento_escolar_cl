{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análisis exploratorio del rendimiento escolar\n",
        "\n",
        "Exploración basada en `data/raw/rendimiento_escolar.csv`, siguiendo los lineamientos del documento `references/PresentacionCaso.pdf`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objetivos del caso\n",
        "\n",
        "- Caracterizar la distribución del `PROM_GRAL` y la `ASISTENCIA` por rangos, resaltando segmentos críticos.\n",
        "- Cruzar desempeño y asistencia con las variables de contexto pedidas (género, dependencia y región) para identificar brechas territoriales o administrativas.\n",
        "- Preparar visualizaciones solicitadas en la guía: barras comparativas, mapas de calor regionales y la relación asistencia vs. rendimiento.\n",
        "- Entrenar una regresión lineal simple que cuantifique los efectos marginales de la asistencia y las variables de contexto sobre el promedio general."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "plt.rcParams[\"figure.dpi\"] = 120\n",
        "pd.options.display.float_format = \"{:,.2f}\".format\n",
        "\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = Path(\"../data/raw/rendimiento_escolar.csv\")\n",
        "\n",
        "# Se especifica el separador decimal y los tipos de datos para optimizar la carga\n",
        "raw_df = pd.read_csv(DATA_PATH, decimal=\",\")\n",
        "df = raw_df.copy()\n",
        "\n",
        "# La columna PROM_GRAL ya se carga como float gracias al parámetro 'decimal'\n",
        "# df[\"PROM_GRAL\"] = (\n",
        "#     df[\"PROM_GRAL\"].astype(str).str.replace(\",\", \".\", regex=False).astype(float)\n",
        "# )\n",
        "\n",
        "region_cols = [c for c in df.columns if c.startswith(\"COD_REG_RBD_\")]\n",
        "dep_cols = [c for c in df.columns if c.startswith(\"COD_DEPE_\")]\n",
        "gender_cols = [c for c in df.columns if c.startswith(\"GEN_ALU_\")]\n",
        "\n",
        "def collapse_one_hot(frame, columns, prefix=\"\", mapping=None):\n",
        "    relevant = frame[columns]\n",
        "    labels = relevant.idxmax(axis=1)\n",
        "    labels = labels.where(relevant.sum(axis=1).gt(0))\n",
        "    labels = labels.str.replace(prefix, \"\", regex=False).str.strip()\n",
        "    if mapping:\n",
        "        labels = labels.map(mapping).fillna(labels)\n",
        "    return labels\n",
        "\n",
        "GEN_MAP = {\n",
        "    \"GEN_ALU_0\": \"Indefinido\",\n",
        "    \"GEN_ALU_1\": \"Masculino\",\n",
        "    \"GEN_ALU_2\": \"Femenino\",\n",
        "    \"GEN_ALU_0\": \"Sin información\",\n",
        "    \"GEN_ALU_3\": \"No Binario\",\n",
        "}\n",
        "\n",
        "df[\"region\"] = collapse_one_hot(df, region_cols, \"COD_REG_RBD_\")\n",
        "df[\"dependencia\"] = collapse_one_hot(df, dep_cols, \"COD_DEPE_\")\n",
        "df[\"genero\"] = collapse_one_hot(df, gender_cols, mapping=GEN_MAP)\n",
        "\n",
        "valid_mask = df[\"PROM_GRAL\"].between(1, 7)\n",
        "df_valid = df[valid_mask].copy()\n",
        "\n",
        "print(f\"Registros totales: {len(df):,}\")\n",
        "print(f\"Registros con PROM_GRAL válido (1-7): {len(df_valid):,} ({len(df_valid)/len(df):.1%})\")\n",
        "display(df_valid[[\"ASISTENCIA\", \"PROM_GRAL\", \"region\", \"dependencia\", \"genero\"]].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Panorama general de la base\n",
        "\n",
        "- `PROM_GRAL` viene con coma decimal y se transforma a flotante.\n",
        "- Se consideran válidos únicamente los promedios en la escala oficial de 1 a 7; los registros fuera del rango se tratan como “sin nota” para los análisis de desempeño.\n",
        "- Se crean las columnas `region`, `dependencia` y `genero` a partir de los indicadores one-hot entregados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_table = (\n",
        "    df_valid[[\"PROM_GRAL\", \"ASISTENCIA\"]]\n",
        "    .describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
        "    .T\n",
        ")\n",
        "metrics_table[\"missing_pct\"] = [\n",
        "    (1 - len(df_valid) / len(df)) * 100,\n",
        "    df_valid[\"ASISTENCIA\"].isna().mean() * 100,\n",
        "]\n",
        "display(metrics_table)\n",
        "\n",
        "context_coverage = (\n",
        "    df_valid[[\"region\", \"dependencia\", \"genero\"]]\n",
        "    .isna()\n",
        "    .mean()\n",
        "    .to_frame(name=\"missing_pct\")\n",
        ")\n",
        "display(context_coverage)\n",
        "\n",
        "corr_global = df_valid[\"PROM_GRAL\"].corr(df_valid[\"ASISTENCIA\"])\n",
        "print(f\"Correlación PROM_GRAL vs. ASISTENCIA: {corr_global:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Distribuciones por rangos\n",
        "\n",
        "La guía solicita caracterizar los tramos de rendimiento y asistencia. Se generan tablas de frecuencia y diagramas de densidad para ambos indicadores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prom_bins = [1, 3, 4, 5, 6, 7.1]\n",
        "prom_labels = [\"1.0-3.0\", \"3.0-4.0\", \"4.0-5.0\", \"5.0-6.0\", \"6.0-7.0\"]\n",
        "df_valid[\"prom_rango\"] = pd.cut(\n",
        "    df_valid[\"PROM_GRAL\"],\n",
        "    bins=prom_bins,\n",
        "    labels=prom_labels,\n",
        "    include_lowest=True,\n",
        ")\n",
        "\n",
        "asistencia_bins = [0, 50, 80, 90, 95, 100]\n",
        "asistencia_labels = [\"0-50\", \"50-80\", \"80-90\", \"90-95\", \"95-100\"]\n",
        "df_valid[\"asistencia_rango\"] = pd.cut(\n",
        "    df_valid[\"ASISTENCIA\"],\n",
        "    bins=asistencia_bins,\n",
        "    labels=asistencia_labels,\n",
        "    include_lowest=True,\n",
        "    right=True,\n",
        ")\n",
        "\n",
        "freq_prom = (\n",
        "    df_valid[\"prom_rango\"]\n",
        "    .value_counts()\n",
        "    .sort_index()\n",
        "    .to_frame(name=\"estudiantes\")\n",
        ")\n",
        "freq_prom[\"pct\"] = 100 * freq_prom[\"estudiantes\"] / freq_prom[\"estudiantes\"].sum()\n",
        "\n",
        "freq_asistencia = (\n",
        "    df_valid[\"asistencia_rango\"]\n",
        "    .value_counts()\n",
        "    .sort_index()\n",
        "    .to_frame(name=\"estudiantes\")\n",
        ")\n",
        "freq_asistencia[\"pct\"] = (\n",
        "    100 * freq_asistencia[\"estudiantes\"] / freq_asistencia[\"estudiantes\"].sum()\n",
        ")\n",
        "\n",
        "display(freq_prom)\n",
        "display(freq_asistencia)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].hist(\n",
        "    df_valid[\"PROM_GRAL\"],\n",
        "    bins=np.arange(1, 7.25, 0.25),\n",
        "    color=\"#1f77b4\",\n",
        "    edgecolor=\"white\",\n",
        ")\n",
        "axes[0].set_title(\"Distribución PROM_GRAL\")\n",
        "axes[0].set_xlabel(\"Nota\")\n",
        "axes[0].set_ylabel(\"Estudiantes\")\n",
        "\n",
        "axes[1].hist(\n",
        "    df[\"ASISTENCIA\"],\n",
        "    bins=np.arange(0, 105, 5),\n",
        "    color=\"#ff7f0e\",\n",
        "    edgecolor=\"white\",\n",
        ")\n",
        "axes[1].set_title(\"Distribución ASISTENCIA\")\n",
        "axes[1].set_xlabel(\"% asistencia anual\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1. Importancia de Variables con Métodos Avanzados (Permutation y SHAP)\n",
        "\n",
        "Para complementar el análisis de coeficientes, aplicaremos dos técnicas más robustas:\n",
        "\n",
        "1.  **Importancia por Permutación**: Mide cuánto empeora el rendimiento del modelo (R²) si \"desordenamos\" aleatoriamente los valores de una variable. Una caída grande en el R² significa que la variable es muy importante.\n",
        "2.  **Valores SHAP**: Es un método basado en teoría de juegos que no solo indica la importancia de una variable, sino también la dirección (positiva o negativa) de su impacto en cada predicción individual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "try:\n",
        "    import shap\n",
        "except ImportError:\n",
        "    print(\"Para usar SHAP, instálalo con: pip install shap\")\n",
        "    shap = None\n",
        "\n",
        "# --- 1. Gráfico de Importancia por Permutación ---\n",
        "perm_result = permutation_importance(\n",
        "    linreg, X_test, y_test, n_repeats=10, random_state=RANDOM_STATE, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Usamos los nombres limpios de coef_df para el gráfico\n",
        "perm_importance_df = pd.DataFrame(\n",
        "    data={\"importance_mean\": perm_result.importances_mean},\n",
        "    index=coef_df[\"feature_clean\"],\n",
        ").sort_values(\"importance_mean\", ascending=True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "perm_importance_df.tail(20).plot(kind=\"barh\", ax=ax, legend=False)\n",
        "ax.set_title(\"Top 20 Variables por Importancia de Permutación\")\n",
        "ax.set_xlabel(\"Caída promedio en el puntaje R²\")\n",
        "ax.set_ylabel(\"Variable\")\n",
        "add_labels_to_barh(ax, fmt=\"{:.4f}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 2. Gráfico de Resumen de SHAP ---\n",
        "if shap:\n",
        "    print(\"\\n--- Análisis con SHAP ---\")\n",
        "    # Para modelos lineales, LinearExplainer es el más eficiente\n",
        "    # Usamos X_train como datos de fondo para el explainer\n",
        "    explainer = shap.LinearExplainer(linreg, X_train)\n",
        "\n",
        "    # Calculamos los valores SHAP sobre el conjunto de prueba\n",
        "    shap_values = explainer(X_test)\n",
        "\n",
        "    # Reemplazamos los nombres largos por los limpios en los datos de SHAP\n",
        "    shap_values.feature_names = coef_df.set_index(\"feature\").loc[shap_values.feature_names][\"feature_clean\"].tolist()\n",
        "\n",
        "    # Gráfico de resumen (summary plot)\n",
        "    shap.summary_plot(\n",
        "        shap_values,\n",
        "        X_test,\n",
        "        max_display=20,\n",
        "        show=False,\n",
        "        plot_size=(10, 8)\n",
        "    )\n",
        "    plt.title(\"Resumen de Impacto de Variables (SHAP)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\nSHAP no está instalado. Omitiendo gráfico de SHAP.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Cruces con variables de contexto\n",
        "\n",
        "Se evalúan medias, dispersiones y tamaños de muestra por dependencia, género y región; luego se derivan visualizaciones comparativas solicitadas en la guía."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarize_context(group_col):\n",
        "    summary = (\n",
        "        df_valid.groupby(group_col)[[\"PROM_GRAL\", \"ASISTENCIA\"]]\n",
        "        .agg([\"mean\", \"std\", \"count\"])\n",
        "        .sort_values((\"PROM_GRAL\", \"mean\"), ascending=False)\n",
        "    )\n",
        "    summary.columns = [f\"{metric}_{stat}\" for metric, stat in summary.columns]\n",
        "    return summary\n",
        "\n",
        "dep_summary = summarize_context(\"dependencia\")\n",
        "gender_summary = summarize_context(\"genero\")\n",
        "region_summary = summarize_context(\"region\")\n",
        "\n",
        "display(dep_summary)\n",
        "display(gender_summary)\n",
        "display(region_summary.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_labels_to_barh(ax, fmt=\"{:.2f}\"):\n",
        "    \"\"\"Añade etiquetas a las barras de un gráfico de barras horizontal.\"\"\"\n",
        "    for bar in ax.patches:\n",
        "        width = bar.get_width()\n",
        "        # Ajustar la posición x para valores negativos\n",
        "        x_pos = width + (ax.get_xlim()[1] * 0.01) if width >= 0 else width - (ax.get_xlim()[1] * 0.05)\n",
        "        ax.text(\n",
        "            x_pos,\n",
        "            bar.get_y() + bar.get_height() / 2,\n",
        "            fmt.format(width),\n",
        "            va='center',\n",
        "        )\n",
        "    # Ajustar límites para dar espacio a las etiquetas\n",
        "    ax.set_xlim(right=ax.get_xlim()[1] * 1.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# --- Gráficos por Dependencia ---\n",
        "dep_summary_sorted = dep_summary.sort_values(\"PROM_GRAL_mean\")\n",
        "\n",
        "# Gráfico para PROM_GRAL por Dependencia\n",
        "dep_summary_sorted[\"PROM_GRAL_mean\"].plot(\n",
        "    kind=\"barh\", ax=axes[0, 0], color=\"#1f77b4\", title=\"Promedio General por Dependencia\"\n",
        ")\n",
        "axes[0, 0].set_xlabel(\"Nota Promedio\")\n",
        "axes[0, 0].set_ylabel(\"Dependencia\")\n",
        "add_labels_to_barh(axes[0, 0])\n",
        "\n",
        "# Gráfico para ASISTENCIA por Dependencia\n",
        "dep_summary_sorted[\"ASISTENCIA_mean\"].plot(\n",
        "    kind=\"barh\", ax=axes[0, 1], color=\"#ff7f0e\", title=\"Asistencia Promedio por Dependencia\"\n",
        ")\n",
        "axes[0, 1].set_xlabel(\"% Asistencia Promedio\")\n",
        "axes[0, 1].set_ylabel(\"\")\n",
        "add_labels_to_barh(axes[0, 1])\n",
        "\n",
        "# --- Gráficos por Región ---\n",
        "region_prom_plot = (\n",
        "    df_valid.groupby(\"region\")[\"PROM_GRAL\"]\n",
        "    .mean()\n",
        "    .sort_values()\n",
        ")\n",
        "region_prom_plot.plot(kind=\"barh\", ax=axes[1, 0], color=\"#2ca02c\")\n",
        "axes[1, 0].set_title(\"Promedio General por Región\")\n",
        "axes[1, 0].set_xlabel(\"Nota Promedio\")\n",
        "axes[1, 0].set_ylabel(\"Región\")\n",
        "add_labels_to_barh(axes[1, 0])\n",
        "\n",
        "region_asistencia_plot = (\n",
        "    df_valid.groupby(\"region\")[\"ASISTENCIA\"]\n",
        "    .mean()\n",
        "    .sort_values()\n",
        ")\n",
        "region_asistencia_plot.plot(kind=\"barh\", ax=axes[1, 1], color=\"#d62728\")\n",
        "axes[1, 1].set_title(\"Asistencia Promedio por Región\")\n",
        "axes[1, 1].set_xlabel(\"% Asistencia Promedio\")\n",
        "axes[1, 1].set_ylabel(\"\")\n",
        "add_labels_to_barh(axes[1, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "heatmap_data = df_valid.pivot_table(\n",
        "    index=\"region\",\n",
        "    columns=\"dependencia\",\n",
        "    values=\"PROM_GRAL\",\n",
        "    aggfunc=\"mean\",\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "im = ax.imshow(heatmap_data.values, aspect=\"auto\", cmap=\"YlOrBr\")\n",
        "ax.set_xticks(range(len(heatmap_data.columns)))\n",
        "ax.set_xticklabels(heatmap_data.columns, rotation=45, ha=\"right\")\n",
        "ax.set_yticks(range(len(heatmap_data.index)))\n",
        "ax.set_yticklabels(heatmap_data.index)\n",
        "ax.set_title(\"Mapa de calor: PROM_GRAL por región y dependencia\")\n",
        "\n",
        "for i in range(heatmap_data.shape[0]):\n",
        "    for j in range(heatmap_data.shape[1]):\n",
        "        value = heatmap_data.values[i, j]\n",
        "        if np.isnan(value):\n",
        "            continue\n",
        "        ax.text(j, i, f\"{value:.2f}\", ha=\"center\", va=\"center\", color=\"black\")\n",
        "\n",
        "fig.colorbar(im, ax=ax, label=\"Nota promedio\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Relación asistencia vs. rendimiento\n",
        "\n",
        "La presentación pide analizar la variación conjunta de ambos indicadores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_por_dependencia = (\n",
        "    df_valid.groupby(\"dependencia\")\n",
        "    .apply(lambda g: g[\"PROM_GRAL\"].corr(g[\"ASISTENCIA\"]))\n",
        "    .to_frame(name=\"corr\")\n",
        "    .sort_values(\"corr\", ascending=False)\n",
        ")\n",
        "display(corr_por_dependencia)\n",
        "\n",
        "sample = (\n",
        "    df_valid.sample(50_000, random_state=RANDOM_STATE)\n",
        "    if len(df_valid) > 50_000\n",
        "    else df_valid\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 6))\n",
        "for dep, data in sample.groupby(\"dependencia\"):\n",
        "    ax.scatter(\n",
        "        data[\"ASISTENCIA\"],\n",
        "        data[\"PROM_GRAL\"],\n",
        "        s=10,\n",
        "        alpha=0.4,\n",
        "        label=dep,\n",
        "    )\n",
        "\n",
        "ax.set_title(\"Asistencia vs. PROM_GRAL (muestra)\")\n",
        "ax.set_xlabel(\"% asistencia anual\")\n",
        "ax.set_ylabel(\"Nota promedio\")\n",
        "ax.legend(title=\"Dependencia\", bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Modelo predictivo: regresión lineal\n",
        "\n",
        "Se ajusta una regresión lineal con la asistencia y los indicadores one-hot de región, dependencia y género. El objetivo es cuantificar los efectos marginales solicitados en la guía y estimar la importancia relativa de cada grupo de variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.metrics import mean_absolute_error, r2_score\n",
        "    import statsmodels.api as sm\n",
        "    from sklearn.model_selection import train_test_split\n",
        "except ImportError as exc:\n",
        "    raise ImportError(\n",
        "        \"Instala scikit-learn (por ejemplo `pip install scikit-learn`) para ejecutar esta celda.\"\n",
        "    ) from exc\n",
        "\n",
        "feature_cols = [\"ASISTENCIA\"] + region_cols + dep_cols + gender_cols\n",
        "\n",
        "# Para evitar multicolinealidad, eliminamos una categoría por cada grupo para que sirva de referencia\n",
        "ref_region = \"COD_REG_RBD_Metropolitana\"\n",
        "ref_dep = \"COD_DEPE_Particular Subvencionado\" # La categoría más común\n",
        "ref_gender = \"GEN_ALU_0\" # Sin información\n",
        "\n",
        "final_region_cols = [c for c in region_cols if c != ref_region]\n",
        "final_dep_cols = [c for c in dep_cols if c != ref_dep]\n",
        "final_gender_cols = [c for c in gender_cols if c != ref_gender]\n",
        "\n",
        "feature_cols_final = [\"ASISTENCIA\"] + final_region_cols + final_dep_cols + final_gender_cols\n",
        "model_df = df_valid.dropna(subset=feature_cols_final + [\"PROM_GRAL\"]).copy()\n",
        "\n",
        "if len(model_df) > 300_000:\n",
        "    model_df = model_df.sample(300_000, random_state=RANDOM_STATE)\n",
        "\n",
        "X = model_df[feature_cols_final]\n",
        "y = model_df[\"PROM_GRAL\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = linreg.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f\"R²: {r2:.3f}\")\n",
        "print(f\"MAE: {mae:.3f}\")\n",
        "print(f\"Intercepto: {linreg.intercept_:.3f}\")\n",
        "\n",
        "# Para obtener los p-values, usamos statsmodels, que está más orientado a la inferencia\n",
        "print(\"\\n--- Resumen del Modelo (statsmodels) ---\")\n",
        "X_train_sm = sm.add_constant(X_train) # Añadir una constante (intercepto) al modelo\n",
        "sm_model = sm.OLS(y_train, X_train_sm).fit()\n",
        "print(sm_model.summary())\n",
        "print(\"-----------------------------------------\")\n",
        "\n",
        "# --- Análisis de Coeficientes del Modelo ---\n",
        "coef_df = pd.DataFrame({\"feature\": feature_cols_final, \"coef\": linreg.coef_})\n",
        "\n",
        "# Limpiar nombres de variables para mejor visualización\n",
        "def clean_feature_name(name):\n",
        "    return (\n",
        "        name.replace(\"COD_REG_RBD_\", \"\")\n",
        "        .replace(\"COD_DEPE_\", \"\")\n",
        "        .replace(\"GEN_ALU_\", \"\")\n",
        "        .replace(\"Subvencionado\", \"Subv.\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "coef_df[\"feature_clean\"] = coef_df[\"feature\"].apply(clean_feature_name)\n",
        "\n",
        "# Clasificar variables por grupo\n",
        "def classify_feature(name):\n",
        "    if name == \"ASISTENCIA\": return \"Asistencia\"\n",
        "    if name.startswith(\"COD_DEPE\"): return \"Dependencia\"\n",
        "    if name.startswith(\"COD_REG_RBD\"): return \"Región\"\n",
        "    if name.startswith(\"GEN_ALU\"): return \"Género\"\n",
        "    return \"Otros\"\n",
        "\n",
        "coef_df[\"grupo\"] = coef_df[\"feature\"].map(classify_feature)\n",
        "coef_df[\"abs_coef\"] = coef_df[\"coef\"].abs()\n",
        "\n",
        "# --- Visualización de Importancia de Variables ---\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 8), sharey=False)\n",
        "\n",
        "# Gráfico 1: Coeficientes más positivos\n",
        "top_positive = coef_df.nlargest(10, \"coef\").sort_values(\"coef\")\n",
        "axes[0].barh(top_positive[\"feature_clean\"], top_positive[\"coef\"], color=\"#2ca02c\")\n",
        "axes[0].set_title(\"Top 10 Variables con Mayor Impacto Positivo\")\n",
        "axes[0].set_xlabel(\"Impacto en PROM_GRAL (valor del coeficiente)\")\n",
        "axes[0].axvline(0, color='grey', linewidth=0.8, linestyle='--')\n",
        "\n",
        "# Gráfico 2: Coeficientes más negativos\n",
        "top_negative = coef_df.nsmallest(10, \"coef\").sort_values(\"coef\", ascending=False)\n",
        "axes[1].barh(top_negative[\"feature_clean\"], top_negative[\"coef\"], color=\"#d62728\")\n",
        "axes[1].set_title(\"Top 10 Variables con Mayor Impacto Negativo\")\n",
        "axes[1].set_xlabel(\"Impacto en PROM_GRAL (valor del coeficiente)\")\n",
        "axes[1].axvline(0, color='grey', linewidth=0.8, linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Gráfico 3: Importancia por grupo de variables\n",
        "importance_by_group = coef_df.groupby(\"grupo\")[\"abs_coef\"].sum().sort_values()\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "importance_by_group.plot(kind=\"barh\", ax=ax, color=\"#1f77b4\")\n",
        "ax.set_title(\"Importancia Agregada por Grupo de Variables\")\n",
        "ax.set_xlabel(\"Suma de Coeficientes Absolutos\")\n",
        "ax.set_ylabel(\"Grupo\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Conclusiones rápidas\n",
        "\n",
        "- El 91 % de los registros presenta promedios válidos y se concentran en el tramo 5.5–6.5; sin embargo, un 9 % carece de nota reportada (0), por lo que conviene monitorear la cobertura de calificaciones.\n",
        "- La asistencia es alta (mediana 91 %), pero un quinto del alumnado cae bajo 90 %, tramo asociado a los promedios más bajos del histograma.\n",
        "- Se observan brechas claras por dependencia: los establecimientos particulares pagados superan los 6.3 puntos y 92 % de asistencia, mientras que las corporaciones municipales y los SLE rondan 5.8 puntos y 87 % de asistencia.\n",
        "- Las regiones extremas (Arica y Magallanes) lideran el rendimiento, mientras que Atacama y Los Lagos muestran los niveles más bajos dentro del mapa de calor.\n",
        "- Las alumnas obtienen ~0.2 puntos más de PROM_GRAL, aunque asisten ligeramente menos; la diferencia se mantiene en todo el espectro de dependencias.\n",
        "- La correlación asistencia–rendimiento es moderada (0.36 global) y se fortalece en dependencias municipales (≈0.40–0.48), lo que respalda priorizar intervenciones de asistencia en esos segmentos.\n",
        "- El modelo lineal incluido permite cuantificar el efecto marginal de cada variable y extraer tablas de importancia relativa para guiar futuras simulaciones de política escolar."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}